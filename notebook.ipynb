{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/Pa/vsIltrHIYU/nNxEYg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dataeducator/capstone/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Project Submission:Capstone\n",
        "(Capstone)\n",
        "\n",
        "- Student Name: Tenicka Norwood\n",
        "- Program Pace: self-paced\n",
        "- Scheduled Project Review Time: Tuesday, September 19, 2023, 12 pm\n",
        "- Instructor name: Morgan Jones\n",
        "- Blog post Url: https://medium.com/mlearning-ai/fueling-student-success-1723abd2991b"
      ],
      "metadata": {
        "id": "cdn2T52V4tmC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project I will be using __CRISP-DM__ process which has six phases:\n",
        "\n",
        "* Business Understanding __&#8594;__ Understanding the project objectives, requirements, and constraints from a business perspective.\n",
        "\n",
        "* Data Understanding __&#8594;__ Exploring and assessing the available data, its quality, structure, and initial insights.\n",
        "\n",
        "* Data Preparation __&#8594;__ Cleaning, transforming, and preparing the data to be used for modeling, including handling missing values and outliers.\n",
        "\n",
        "* Modeling __&#8594;__ Selecting and applying appropriate machine learning algorithms or techniques to build predictive or descriptive models.\n",
        "\n",
        "* Evaluation __&#8594;__ Assessing the performance of the models and determining their suitability for solving the business problem.\n",
        "\n",
        "* Deployment __&#8594;__ Integrating the chosen model into the business environment, making it accessible for end-users."
      ],
      "metadata": {
        "id": "tg7jRLIIQRaJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Business Understanding\n"
      ],
      "metadata": {
        "id": "0LQdzJxA5BS5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### __Disclaimer:__\n",
        "This Jupyter notebook and its contents are __intended solely for educational purposes__. The included business case and the results of the deep learning models should not be interpreted as medical advice, and have not received endorsement or approval from any professional or medical organization.\n",
        "\n",
        "The models and outcomes presented here are for illustrative purposes __only__. Users should __not__ use these models or their outcomes for making real-world decisions without consulting appropriate domain experts and medical professionals. Any actions taken based on the information in this notebook are at the user's own risk.\n",
        "The author and contributors of this notebook disclaim any liability for the accuracy, completeness, or efficacy of the information provided."
      ],
      "metadata": {
        "id": "GpKnn92FWdJR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Understanding\n",
        "\n",
        "## __Metrics__\n",
        "We will prioritize recall in this project over accuracy. We will also aim for balance between recall (sensitivity) while maintaining a high level of precision (specificity). With these objectives in mind, we aim to reduce the number of false positives and increase the model's ability to correctly identify patients with pneumonia. In this context, false positives could lead to unnecessary treatment or interventions.\n",
        "\n",
        "\n",
        "* __True Positives (TP)__: The model correctly predicted one of the positive classes (glioma_tumor, pituitary_tumor, or meningioma_tumor).\n",
        "\n",
        "* __True Negatives (TN):__ This metric is not applicable in multi-class classification, as it is specific to binary classification where there are only two classes.\n",
        "\n",
        "* __False Positives (FP):__ The model predicted one of the positive classes, but it was incorrect.\n",
        "\n",
        "* __False Negatives (FN):__ The model failed to predict one of the positive classes.\n",
        "\n",
        "<br>\n",
        "\\begin{gathered}   \n",
        "Precision =  \\frac{True\\ Positive}{True\\ Positive + False\\ Positive}\n",
        "\\end{gathered}\n",
        "<br>\n",
        "\n",
        "</br>\n",
        "\n",
        "</br>\n",
        "\\begin{gathered}\n",
        "Recall = \\frac{True\\ Positive}{False\\ Negative + True\\ Positive}\n",
        "\\end{gathered}\n",
        "<br>\n",
        "\n",
        "A high precision indicates that when our model predicts the presence of a tumor, the patient will likely have a tumor.\n",
        "<br>"
      ],
      "metadata": {
        "id": "3axmg4wq5W_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading and Preparing  Dataset for Deep Learning Analysis\n",
        "1. __Create or Log in to Your Kaggle Account:__\n",
        "    If you do not already have a Kaggle account, create one. If you have an account log in.\n",
        "2. __Access the Pneumonia Dataset:__\n",
        "    Go to the following direct link to access dataset on Kaggle: [Dataset](https://www.kaggle.com/datasets/)\n",
        "3. __Download the Dataset:__\n",
        "    On the dataset page, you will see a \"Download\" button. Click on it to download the dataset.\n",
        "   The dataset is approximately __2GB__.\n",
        "\n",
        "4. __Unzip the file Add the unzipped archive to your Google Drive:__\n",
        "    After downloading and unzipping the dataset you'll have a folder named 'archive'. This folder contains the dataset. To use this notebook you will need to provide the location of the .zip file in your Google Drive.\n",
        "\n",
        "5. __Run the next two cells without making any chages__\n",
        "    Mount your google drive to allow colab access to your google drive.\n",
        "    Unzip the file so you can use the contents of this notebook.\n",
        "    The file should include train, test and val folders that contain subfolders with  and images."
      ],
      "metadata": {
        "id": "xmsvGlQ-lQrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run cell without making any changes\n",
        "from google.colab import drive\n",
        "\n",
        "class ObtainData:\n",
        "  \"\"\"\n",
        "  A class to obtain dataset location from Google Drive.\n",
        "\n",
        "  Usage:\n",
        "  data_obtainer = ObtainData()\n",
        "  dataset_location = data_obtainer.get_dataset_location()\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "      self.drive_mounted = False\n",
        "\n",
        "  def mount_drive(self):\n",
        "    \"\"\"\n",
        "    Mounts Google Drive to '/content/drive'.\n",
        "    \"\"\"\n",
        "    drive.mount('/content/drive')\n",
        "    self.drive_mounted = True\n",
        "\n",
        "  def get_dataset_location(self):\n",
        "    \"\"\"\n",
        "    Prompts the user to enter the location of the datset folder in their Google Drive.\n",
        "    Returns the full file path of the dataset location.\n",
        "    \"\"\"\n",
        "\n",
        "    while True:\n",
        "      # Munt Google Drive if not already mounted\n",
        "      if not self.drive_mounted:\n",
        "        self.mount_drive()\n",
        "\n",
        "      # Provide a template for the user input\n",
        "      example_input =\"/MyDrive/Your_Folder_name/\"\n",
        "      dataset_location = input(f\"Enter the location of the dataset folder in your Google Drive (e.g., {example_input}):\")\n",
        "      file_path = f'/content/drive{dataset_location}'\n",
        "\n",
        "      # Check if the file exists\n",
        "      if os.path.exists(file_path):\n",
        "        print(f\" The file '{dataset_location}' exists in your Google Drive.\")\n",
        "        return file_path\n",
        "      else:\n",
        "        print(f\" The file '{dataset_location}' does not exist in your Google Drive. Please try again.\")"
      ],
      "metadata": {
        "id": "RXcB4Zby5gZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run cell without making any changes\n",
        "# Create an instance of the ObtainData class\n",
        "data_obtainer = ObtainData()\n",
        "\n",
        "# Get the dataset location\n",
        "dataset_location = data_obtainer.get_dataset_location()\n",
        "print(f\"Datatset location\")"
      ],
      "metadata": {
        "id": "xs4xRzGbrzAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation\n"
      ],
      "metadata": {
        "id": "0YWh9ixf5h9S"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EVaL9lSY5kKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling\n"
      ],
      "metadata": {
        "id": "FpA58RjL5rMG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "msBJUZE_5uId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation\n"
      ],
      "metadata": {
        "id": "dn_leZJn5zk2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AwXLzrr452d1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deployment"
      ],
      "metadata": {
        "id": "CW8MxReL52_f"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-csn0D_w54RN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}